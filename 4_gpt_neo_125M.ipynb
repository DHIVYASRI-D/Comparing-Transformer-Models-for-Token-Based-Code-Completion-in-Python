{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzcc8Bsn4JZtixBtv6OAMe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DHIVYASRI-D/Comparing-Transformer-Models-for-Token-Based-Code-Completion-in-Python/blob/main/4_gpt_neo_125M.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Install dependencies"
      ],
      "metadata": {
        "id": "0SSQsX_NsEu-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoC8Wf_Ir7md"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets evaluate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "install librarires"
      ],
      "metadata": {
        "id": "Z4f-o3iTsJUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets --quiet\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "from datasets import load_dataset\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "YP1tl0yKtLS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load your pre-tokenized dataset (same subset for fair comparison)"
      ],
      "metadata": {
        "id": "KB2pWk3wsMXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"code_search_net\", \"python\")\n",
        "small_train_dataset = dataset[\"train\"].select(range(1000))\n",
        "small_val_dataset = dataset[\"validation\"].select(range(200))\n"
      ],
      "metadata": {
        "id": "Tbz4Gg75tU72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Load Tokenizer & Model"
      ],
      "metadata": {
        "id": "uq6kkvlqsRAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt = \"EleutherAI/gpt-neo-125M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_ckpt)\n",
        "\n",
        "# Fix for padding\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n"
      ],
      "metadata": {
        "id": "_gmMXv_RsStU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization\n"
      ],
      "metadata": {
        "id": "DktiUVZ9sT7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    tokens = tokenizer(examples[\"func_code_string\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
        "    return tokens\n",
        "\n",
        "\n",
        "tokenized_train = small_train_dataset.map(tokenize_function, batched=True, remove_columns=small_train_dataset.column_names)\n",
        "tokenized_val = small_val_dataset.map(tokenize_function, batched=True, remove_columns=small_val_dataset.column_names)\n"
      ],
      "metadata": {
        "id": "9ZWJbirWsV28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Format for PyTorch"
      ],
      "metadata": {
        "id": "UFnB3NfxsZf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train.set_format(\"torch\")\n",
        "tokenized_val.set_format(\"torch\")\n"
      ],
      "metadata": {
        "id": "e58HqTTFscMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Arguments and Trainer"
      ],
      "metadata": {
        "id": "NrixXh9uuEUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gptneo-results\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=1,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        ")\n"
      ],
      "metadata": {
        "id": "FiqnXGv1uGPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Train"
      ],
      "metadata": {
        "id": "h-2pUo5QuK8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "gT-2JUqDuL_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Code"
      ],
      "metadata": {
        "id": "m1FEhX20v6NA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from datasets import load_dataset\n",
        "\n",
        "def evaluate_gptneo(model, tokenizer, dataset):\n",
        "    model.eval()\n",
        "    model.to(\"cuda\")\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for item in tqdm(dataset.select(range(200))):  # limit eval to 200 samples\n",
        "        input_ids = tokenizer.encode(item[\"func_code_string\"], return_tensors=\"pt\", truncation=True, max_length=128).to(\"cuda\")\n",
        "\n",
        "        if input_ids.size(1) < 2:\n",
        "            continue  # skip too-short inputs\n",
        "\n",
        "        inputs = input_ids[:, :-1]\n",
        "        labels = input_ids[:, 1:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=inputs)\n",
        "            logits = outputs.logits\n",
        "\n",
        "        shift_logits = logits[:, :-1, :].contiguous()\n",
        "        shift_labels = labels[:, :shift_logits.size(1)].contiguous()\n",
        "\n",
        "        loss = loss_fn(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        predictions = torch.argmax(shift_logits, dim=-1)\n",
        "        correct += (predictions == shift_labels).sum().item()\n",
        "        total += shift_labels.numel()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    perplexity = math.exp(total_loss / len(dataset.select(range(200))))\n",
        "    return accuracy, perplexity\n",
        "\n",
        "# Reload raw dataset for 'func_code_string'\n",
        "dataset = load_dataset(\"code_search_net\", split=\"train\", name=\"python\")\n",
        "dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
        "small_val_dataset = dataset[\"test\"].select(range(200))\n",
        "\n",
        "# Run evaluation\n",
        "accuracy, perplexity = evaluate_gptneo(model, tokenizer, small_val_dataset)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Perplexity: {perplexity:.4f}\")\n"
      ],
      "metadata": {
        "id": "0Pwvdp9wv56A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save"
      ],
      "metadata": {
        "id": "cZPbSA_myKI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/gptneo-125M-codecompletion\")\n",
        "tokenizer.save_pretrained(\"/content/gptneo-125M-codecompletion\")\n"
      ],
      "metadata": {
        "id": "L2FPpSGXyJcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "save in Drive"
      ],
      "metadata": {
        "id": "MWN8z-UDySxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "SQOONAL3yUyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/token-completion-models/gptneo-125M\"\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n"
      ],
      "metadata": {
        "id": "U3Dacr2JyaGE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}