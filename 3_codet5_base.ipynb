{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4DQQsJtBBq7HPuWnX+TsV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DHIVYASRI-D/Comparing-Transformer-Models-for-Token-Based-Code-Completion-in-Python/blob/main/3_codet5_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETUP & INSTALL\n"
      ],
      "metadata": {
        "id": "aOVmUAYbhxnq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CecALh-ho8P",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets evaluate accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT LIBRARIES"
      ],
      "metadata": {
        "id": "QoZWH_7KAGsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "import math"
      ],
      "metadata": {
        "id": "_MP6GxiXAJtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD DATA"
      ],
      "metadata": {
        "id": "Vhqbr16nh0_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "id": "n9mr5EbMBTSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"code_search_net\", \"python\")\n",
        "train_data = dataset[\"train\"].select(range(1000))\n",
        "val_data = dataset[\"validation\"].select(range(200))"
      ],
      "metadata": {
        "id": "EdxWmb9ejsAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load tokenizer and mode"
      ],
      "metadata": {
        "id": "VRjtbAhOh8da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"Salesforce/codet5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "qphPxMu2iELo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess function (token-level shifting)"
      ],
      "metadata": {
        "id": "syT68HfJiGRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(example):\n",
        "    code = example[\"func_code_string\"]\n",
        "    tokens = tokenizer(code, truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "    input_ids = tokens[\"input_ids\"]\n",
        "    labels = input_ids[1:] + [tokenizer.pad_token_id]  # Shift left\n",
        "    inputs = input_ids[:-1] + [tokenizer.pad_token_id]\n",
        "\n",
        "    # Mask pad tokens\n",
        "    labels = [label if label != tokenizer.pad_token_id else -100 for label in labels]\n",
        "\n",
        "    tokens[\"input_ids\"] = inputs\n",
        "    tokens[\"labels\"] = labels\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "9sfB8tmPiJZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize datasets"
      ],
      "metadata": {
        "id": "dZZ8eKdhiLcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = train_data.map(preprocess, remove_columns=train_data.column_names)\n",
        "tokenized_val = val_data.map(preprocess, remove_columns=val_data.column_names)"
      ],
      "metadata": {
        "id": "Kz6MgPwsiNs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data collator for padding"
      ],
      "metadata": {
        "id": "hy8J95gxiQLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
      ],
      "metadata": {
        "id": "_jkrj_5XiSyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training setup"
      ],
      "metadata": {
        "id": "ahP_M42BAyJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./codet5-base-results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    predict_with_generate=False,\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "Hai632w-l3NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer"
      ],
      "metadata": {
        "id": "Z-ki1uo1A5TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "EHTHFSdLqLoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "qej3fDjWA_kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "NMOma_TnBCO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation function"
      ],
      "metadata": {
        "id": "KqZyrSczBFC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_codeT5(model, tokenizer, eval_dataset):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    for i in range(len(eval_dataset)):\n",
        "        input_ids = torch.tensor(eval_dataset[i][\"input_ids\"]).unsqueeze(0)\n",
        "        labels = torch.tensor(eval_dataset[i][\"labels\"]).unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids, labels=labels)\n",
        "            logits = outputs.logits\n",
        "            loss = outputs.loss\n",
        "\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        mask = labels != -100\n",
        "\n",
        "        correct += ((predictions == labels) & mask).sum().item()\n",
        "        total += mask.sum().item()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0.0\n",
        "    perplexity = math.exp(total_loss / len(eval_dataset))\n",
        "    return accuracy, perplexity"
      ],
      "metadata": {
        "id": "ULUrzeyPBHG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "tWlvF0R2BK5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, perplexity = evaluate_codeT5(model, tokenizer, tokenized_val)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Perplexity: {perplexity:.4f}\")"
      ],
      "metadata": {
        "id": "dzLgTfZpBNEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a directory to save\n",
        "save_dir = \"./codeT5-base-finetuned\"\n",
        "\n",
        "# Save model\n",
        "model.save_pretrained(save_dir)\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {save_dir}\")\n"
      ],
      "metadata": {
        "id": "N2MgPgoBqlCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "3Xl2A_RIq-qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"/content/drive/MyDrive/fine-tuned-models/codeT5-base-finetuned\"\n",
        "model.save_pretrained(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "print(f\"Model and tokenizer saved permanently to {save_dir}\")\n"
      ],
      "metadata": {
        "id": "dGmYfelFrEH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI"
      ],
      "metadata": {
        "id": "89x8QMk7Y0UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "U1sVYEqnY6pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load fine-tuned CodeT5 model\n",
        "model_dir = \"/content/drive/MyDrive/fine-tuned-models/codeT5-base-finetuned\"\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_dir).to(\"cpu\").eval()\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "# Prediction function\n",
        "def predict_codet5(input_code, max_tokens):\n",
        "    prompt = f\"# Python 3\\n# Complete the following function:\\n{input_code.strip()}\\n\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    outputs = model.generate(\n",
        "    input_ids=inputs.input_ids,\n",
        "    attention_mask=inputs.attention_mask,\n",
        "    max_length=max_tokens,\n",
        "    num_beams=5,\n",
        "    early_stopping=True\n",
        "    )\n",
        "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "\n",
        "# Gradio UI with a slider\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Code Completion with Fine-Tuned CodeT5\")\n",
        "    code_input = gr.Textbox(label=\"Enter partial Python function\", lines=5, placeholder=\"e.g., def add(a, b):\")\n",
        "    token_slider = gr.Slider(minimum=32, maximum=128, value=64, step=1, label=\"Max Tokens to Generate\")\n",
        "    output = gr.Textbox(label=\"Predicted Completion\")\n",
        "\n",
        "    btn = gr.Button(\"Generate\")\n",
        "    btn.click(fn=predict_codet5, inputs=[code_input, token_slider], outputs=output)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "2bvqUP20YSoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# checking"
      ],
      "metadata": {
        "id": "OXimtC74cUP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# Load the raw CodeT5-base model and tokenizer from Hugging Face\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-base\").to(\"cpu\").eval()\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n"
      ],
      "metadata": {
        "id": "w-U2zIvWchY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_codet5(input_code, max_tokens):\n",
        "    prompt = f\"code completion: {input_code.strip()}\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs.input_ids,\n",
        "        attention_mask=inputs.attention_mask,\n",
        "        max_length=max_tokens,\n",
        "        do_sample=True,           # Sampling ON\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return decoded\n"
      ],
      "metadata": {
        "id": "cJk_g-z2cZGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Code Completion with Raw CodeT5-Base\")\n",
        "    code_input = gr.Textbox(label=\"Enter partial Python code\", lines=5)\n",
        "    token_slider = gr.Slider(minimum=16, maximum=128, value=64, step=1, label=\"Max Tokens\")\n",
        "    output = gr.Textbox(label=\"Predicted Completion\")\n",
        "\n",
        "    btn = gr.Button(\"Generate\")\n",
        "    btn.click(fn=predict_codet5, inputs=[code_input, token_slider], outputs=output)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "7zfJgytKcfH7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}